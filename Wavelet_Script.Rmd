---
title: "2021_Wavelets"
output:
  word_document: default
  html_document: default
---

```{r, include=F}
knitr::opts_chunk$set(echo = TRUE)
# Data wrangling packages
library(tidyverse)
library(ggplot2)
library(lubridate)
library(patchwork)
library(astsa)
library(weathermetrics)

# Time series analysis packages
library(MARSS)
library(MASS)
library(forecast)
library(zoo)
library(imputeTS) 
library(WaveletComp)
```

#Import historical data
#ALEXANDER
##Read in Data
```{r, results = F}
# Water temperature - response variable
# Hourly temperature time series dataset from Alexander Pond called "APH" (Alexander Pond Historical) 
# Includes data from 16 December 2010 to 24 November 2021
# Data collected by Mid Klamath Watershed Council, see metadata for more details

APH <- read.csv("Alexander_Historical_2.csv")
APH$date <- lubridate::mdy_hm(APH$Date_Time) #convert dates to POSIXct format and bin by hour

#Check for missing data
missing_data <- APH[!complete.cases(APH),] 
missing_data 

#Bin data by hour
APH$hour <- lubridate::round_date(APH$date, unit="hour") 
head(APH) #check the dataset start date, use for "hour" sequence
tail(APH) #check the dataset end date, use for "hour" sequence

#Create hourly sequence to ensure all missing data is accounted for
hour <- seq(mdy_h('12/16/2010 13'),mdy_h('11/24/2021 14'),by = "hour") #Create an object that goes hour by hour for the entire time series 
hour <- as.data.frame(hour) 
APH <- left_join(hour, APH) 
missing_data <- APH[!complete.cases(APH),] 
missing_data 

#z score s
APH$zTemp <- zscore(APH$Temp)

#Convert to time series
APH_ts <- ts(APH$zTemp, start = c(351, 13), frequency = 24) # This time series starts on 16 Dec 2010 at~13:00, so it starts on day 351 at hour 13 and the frequency is 24 (24 hours per day)
ts.plot(APH_ts,main="Temperature",ylab = "Temperature (C)", xlab = "Time")
```

##Interpolate missing data
```{r, cache = TRUE}
#Run ARIMA to interpolate missing data
y <- APH_ts
date_s <- APH$hour
y_na <- ifelse(is.na(y),0,NA)

fit <- auto.arima(y,trace=TRUE) #fit limited number of models (faster)
summary(fit) #Take a closer look at the best fitted model
forecast_fit <- forecast(y,model=fit) #Predict values using the calibration dataset
```

##Plot interpolated data
```{r}
#Plot the observed and interpolated temperature regimes
par(mar=c(2,4,1,1)) 
plot(date_s,y,xlab="Time",ylab="Temp",lwd=2,type="l") 
lines(date_s,forecast_fit$fitted,col="steelblue")

#Plot predicted versus observed values
scatter.smooth(y,forecast_fit$fitted,xlab="Observed",ylab="Predicted",pch=".",main = "Temperature")
abline(0,1,lty=2)
R2 = round(cor.test(y,forecast_fit$fitted,na.rm=T)$estimate^2,2)
mtext(side=3,line=-2,adj=0.1,bquote(R^2 == .(R2)))
```

##Check residuals of interpolated data
```{r}
checkresiduals(fit) #also gives the results for the Ljung_Box test with H0 = randomly distributed errors (white noise)

#plot residuals versus fitted values (=check for heterosedasticity)
par(mar=c(4,4,4,4))
scatter.smooth(forecast_fit$fitted,forecast_fit$residuals,pch = ".",ylab="Residuals",xlab="Fitted values")
```


##Smooth interpolated data
```{r, cache = TRUE}
#Interpolate missing values using a Kalman filter (=smoother)
y_inter <- na_kalman(y,model=fit$model) 

#Plot the results
par(mar=c(2,4,1,1))
plot(y_inter,xlab="",ylab="Temperature (C)",col="steelblue",main="Interpolation missing values")
lines(y,col="black")
```

##Format interpolated time series into a dataframe
```{r, results = F}
#Put the interpolated temperature dataset (y_inter) into a dataset with the correct dates 
x <- as.data.frame(y_inter) #change y_inter from a ts object to a dataframe
x$ID <- seq.int(nrow(x)) #add a unique ID
date <- as.data.frame(APH$hour) #make the unique "hour" index from APH into a separate dataframe
date$ID <- seq.int(nrow(date)) #create unique ID that aligns with x
y_inter_df <- merge(x,date,"ID") #merge the two dataframes
colnames(y_inter_df)<-c("ID","temp","date") #rename columns
saveRDS(y_inter_df,"y_inter_df.rds")
```
##Check for NAs
```{r}
missing_data <- y_inter_df[!complete.cases(y_inter_df),] 
missing_data 
```
##Wavelet
```{r}
APH.w <- analyze.wavelet(y_inter_df, "temp",
                        loess.span = 0,
                        dt = 1/24, 
                        make.pval = TRUE, n.sim = 1000,
                        date.format = "%Y-%m-%d-%h") 
str(APH.w)
saveRDS(APH.w,"APH.w.rds")

```

##Wavelet Image
```{r}
#read in data as needed
##Note: APH.w saved locally, NOT on github (too big)
APH.w <- readRDS("APH.w.rds")

png("Fig_APH_Wavelet.png", width = 800, height = 500)
wt.image(APH.w, color.key = "quantile", n.levels = 250, main = "Alexander Pond Wavelet",  
         legend.params = list(lab = "wavelet power levels", mar = 6.5, lab.line=4, label.digits = 4), label.time.axis=TRUE,show.date=TRUE,
         periodlab = "period (days)")
dev.off()
```

##Pull 24 hr period
```{r}
#read in data as needed
y_inter_df <- readRDS("y_inter_df.rds")

#create a dataframe of power and of date
power_day <- as.data.frame(APH.w$Power[71,])
power_day <- cbind(power_day, y_inter_df$date)
colnames(power_day) <- c("power","date")

png("Fig_APH_Power.png",width = 800, height = 200)
plot.ts(APH.w$Power[71,])
ggplot()+
  geom_line(data = power_day, aes(x = date, y = power))+
  labs(x = "Date",
       y = "Power")+
  theme_classic()+
  theme(text=element_text(size=16))
dev.off()

```
##Put both graphs together
```{r}
layout(matrix(c(1,2), 2, 1),
   widths=c(3,3), heights=c(2,1))

wt.image(APH.w, color.key = "quantile", n.levels = 250, main = "Alexander Pond Wavelet",  
         legend.params = list(lab = "wavelet power levels", mar = 6.5, lab.line=4, label.digits = 4), label.time.axis=TRUE,show.date=TRUE,
         periodlab = "period (days)")
ggplot()+
  geom_line(data = power_day, aes(x = date, y = power))+
  labs(x = "Date",
       y = "Power")+
  theme_classic()+
  theme(text=element_text(size=16))
```

#STENDER
##Read in Data
```{r, results = F}
# Water temperature - response variable
# Hourly temperature time series dataset from Stender Pond called "SPH" (Stender Pond Historical) 
# Includes data from 16 December 2010 to 24 November 2021
# Data collected by Mid Klamath Watershed Council, see metadata for more details

SPH <- read.csv("Stender_Historical_2.csv")
SPH$date <- lubridate::mdy_hm(SPH$Date_Time) #convert dates to POSIXct format and bin by hour

#Check for missing data
missing_data <- SPH[!complete.cases(SPH),] 
missing_data 

#Bin data by hour
SPH$hour <- lubridate::round_date(SPH$date, unit="hour")
head(SPH) #check the dataset start date, use for "hour" sequence
tail(SPH) #check the dataset end date, use for "hour" sequence

#Create hourly sequence to ensure all missing data is accounted for
hour <- seq(mdy_h('12/16/2010 13'),mdy_h('11/24/2021 14'),by = "hour") #Create an object that goes hour by hour for the entire time series 
hour <- as.data.frame(hour) 
SPH <- left_join(hour, SPH) 
missing_data <- SPH[!complete.cases(SPH),] 
missing_data 

#z score 
SPH$zTemp <- zscore(SPH$Temp)

#Convert to time series
SPH_ts <- ts(SPH$zTemp, start = c(351, 13), frequency = 24) # This time series starts on 16 Dec 2010 at~13:00, so it starts on day 351 at hour 13 and the frequency is 24 (24 hours per day)
ts.plot(SPH_ts,main="Temperature",ylab = "Temperature (C)", xlab = "Time")
```

##Interpolate missing data
```{r, cache = TRUE}
#Run ARIMA to interpolate missing data
y2 <- SPH_ts
date_s2 <- SPH$hour
y_na2 <- ifelse(is.na(y2),0,NA)

fit2 <- auto.arima(y2,trace=TRUE) #fit limited number of models (faster)
summary(fit2) #Take a closer look at the best fitted model
forecast_fit2 <- forecast(y2,model=fit2) #Predict values using the calibration dataset

```

##Plot interpolated data
```{r}
#Plot the observed and interpolated temperature regimes
par(mar=c(2,4,1,1)) 
plot(date_s2,y2,xlab="Time",ylab="Temp",lwd=2,type="l") 
lines(date_s2,forecast_fit2$fitted,col="steelblue")

#Plot predicted versus observed values
scatter.smooth(y2,forecast_fit2$fitted,xlab="Observed",ylab="Predicted",pch=".",main = "Temperature")
abline(0,1,lty=2)
R2 = round(cor.test(y2,forecast_fit2$fitted,na.rm=T)$estimate^2,2)
mtext(side=3,line=-2,adj=0.1,bquote(R^2 == .(R2)))
```

##Check residuals of interpolated data
```{r}
#Check residuals of the interpolation process
checkresiduals(fit2) #also gives the results for the Ljung_Box test with H0 = randomly distributed errors (white noise)

#plot residuals versus fitted values (=check for heterosedasticity)
par(mar=c(4,4,4,4))
scatter.smooth(forecast_fit2$fitted,forecast_fit2$residuals,pch = ".",ylab="Residuals",xlab="Fitted values")
```

##Smooth interpolated data
```{r, cache = TRUE}
#Interpolate missing values using a Kalman filter (=smoother)
y_inter2 <- na_kalman(y2,model=fit2$model) 

#Plot the results
par(mar=c(2,4,1,1))
plot(y_inter2,xlab="",ylab="Temperature (C)",col="steelblue",main="Interpolation missing values")
lines(y2,col="black")
```

##Format interpolated time series into a dataframe
```{r, results = F}
#Put the interpolated temperature dataset (y_inter) into a dataset with the correct dates (
x2 <- as.data.frame(y_inter2) #change y_inter from a ts to a dataframe
x2$ID <- seq.int(nrow(x2)) #add a unique ID, check it is correct length
date2 <- as.data.frame(SPH$hour) #make the unique "hour" index from SPH into a separate dataframe
date2$ID <- seq.int(nrow(date2)) #give that a unique ID that aligns with x
y_inter2_df <- merge(x2,date2,"ID") #merge the two dataframes
colnames(y_inter2_df)<-c("ID","temp","date") #rename columns
saveRDS(y_inter2_df,"y_inter2_df.rds")
```
##Check for NAs
```{r}
missing_data <- y_inter2_df[!complete.cases(y_inter2_df),] 
missing_data 
```
##Wavelet
```{r}
#run the wavelet
SPH.w <- analyze.wavelet(y_inter2_df, "temp",
                        loess.span = 0,
                        dt = 1/24, 
                        make.pval = TRUE, n.sim = 1000,
                        date.format = "%Y-%m-%d-%h") 
str(SPH.w) # Output
saveRDS(SPH.w,"SPH.w.rds")
```

##Wavelet Image
```{r}
#read in data as needed
##Note: SPH.w saved locally, NOT on github (too big)
SPH.w <- readRDS("SPH.w.rds")

png("Fig_SPH_Wavelet.png", width = 800, height = 500)
wt.image(APH.w, color.key = "quantile", n.levels = 250, main = "Stender Pond Wavelet",  
         legend.params = list(lab = "wavelet power levels", mar = 6.5, lab.line=4, label.digits = 4), label.time.axis=TRUE,show.date=TRUE,
         periodlab = "period (days)")
dev.off()
```

##Pull 24 hr period
```{r}
#read in data as needed
y_inter2_df <- readRDS("y_inter2_df.rds")

#create a dataframe of power and of date
power_day2 <- as.data.frame(SPH.w$Power[71,])
power_day2 <- cbind(power_day2, y_inter2_df$date)
colnames(power_day2) <- c("power","date")

png("Fig_SPH_Power.png",width = 800, height = 200)
ggplot()+
  geom_line(data = power_day2, aes(x = date, y = power))+
  labs(x = "Date",
       y = "Power")+
  theme_classic()+
  theme(text=element_text(size=16))
dev.off()

```

